{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976d3d1e-9d87-44c9-8a12-c1603815184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d36bdc9-68b4-4dd9-be8b-3973b362ad76",
   "metadata": {},
   "source": [
    "### 1. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f436bed0-5fdb-4460-9537-5b4941483947",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/premiums_young_with_gr.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "pd.read_excel(\"../dataset/premiums_young_with_gr.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc055ac-7bf8-475c-b0de-c15ec1d04c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239610ef-face-433b-ba23-a9d3164e8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821797d8-0fb5-45cc-bcef-42fa7f2ee0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_').str.lower() ## snake case convention and removing spaces\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a54a16c-d3f2-4786-acae-40a53fc8e7b8",
   "metadata": {},
   "source": [
    "### 2. EDA & data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b211492f-05b2-4485-9d16-89e8682ebd34",
   "metadata": {},
   "source": [
    "#### i. Handling na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d7766-cc95-40af-a51f-fe3c6ed140a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3d0c3-ab10-4a71-9174-9b74d72c37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True) ## very few na as no of rows = 50k. we can just drop them.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f09b8d-5486-460c-984c-05f29ffa2652",
   "metadata": {},
   "source": [
    "#### ii. Handling duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c331e9-cfc9-48de-88b1-3bc53a7924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() ##no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9015d17-05be-4519-a961-9f653db1bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True) ## we can till keep the code because if tomorrow the file is updated and it has duplicaytes then we'll have handling code.\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5d9bb-8b89-42b1-8bfc-25379a98916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bea861-7e80-46c4-ad97-601172812876",
   "metadata": {},
   "outputs": [],
   "source": [
    "## max age = 356.000000, min number_of_dependants = -3, max income_lakhs = 930 (9.3 cr) | These are or can be outliers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55361728-60db-4aba-aa72-e7b935733b5e",
   "metadata": {},
   "source": [
    "#### iii. Data Cleaning: number_of_dependants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f6bf0-65f6-4baf-b9da-1b54bdbce35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.number_of_dependants<0].shape ## 73 values have no of dependents as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67d3c5-5f18-4d85-9005-222e881e5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_dependants'][df.number_of_dependants < 0].unique() ## 72 rows have these values. Maybe +ve values converted to negative by mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c75036-2935-4290-96e7-e3f039b886e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_dependants'] = abs(df['number_of_dependants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647e95f-2b08-4025-82ce-df7dfb61f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.number_of_dependants.describe()  # now looking good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95372d97-9edd-4bfa-a2b8-c134ed3dab18",
   "metadata": {},
   "source": [
    "#### iii. Data Cleaning: visualizing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806841d-6a73-4651-aa00-27a10b1ce51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = df['age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377e917-1405-4b02-ae50-2f900fb004eb",
   "metadata": {},
   "source": [
    "## Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b962d-28ea-4655-90e8-50736e44e318",
   "metadata": {},
   "source": [
    "### Univariate Analysis: Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f4269-66b1-49b8-abed-13728ab6300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for all numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b42c91-2215-4289-8aed-3c800c779b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(['float64','int64']).columns\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321d942-72b6-4405-b458-3a80f8d64074",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_columns:\n",
    "    plt.figure(figsize=(12, 3)) \n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df8d3e-6d0e-4146-a7a3-4a7f5a7eec98",
   "metadata": {},
   "source": [
    "### iv. Outlier Treatment: Age Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc096e7-8ac6-4bf2-8236-f6edd488f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'][df.age > 100].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5026f9-c5d0-48ae-b7c9-86ad4797f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.age<=100].copy() ## row filtering and then copying into a new df just for safety\n",
    "df1.describe()  ## outliers gone from age column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca1261-74fc-4dc8-8cc0-c2a1837141c4",
   "metadata": {},
   "source": [
    "### iv. Outlier Treatment: Income Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5b436-c430-48c4-a3e3-6ee26b84b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df1.income_lakhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624ea9f-071c-4146-b738-46273d020348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.income_lakhs.quantile([0.25, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd277d-4f1e-40f7-86e0-21d7c4e4275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iqr_bounds(col):\n",
    "    Q1, Q3 = col.quantile([0.25, 0.75])\n",
    "    IQR = Q3-Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "lower, upper = get_iqr_bounds(df1['income_lakhs'])\n",
    "lower, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae39edc-99b8-407f-a5e5-fdf1ff95f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we don't have to worry about the lower bound as anywats our minimun income is 1 lakh which is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4336d-63ca-40d7-b145-02f2fdb0d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.income_lakhs>upper].shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e10b6fbc-f9e0-4833-8903-a4f7924a3cf9",
   "metadata": {},
   "source": [
    "There are many legitimate records that we will get rid of if we use IQR bounds method. Therefore we can also  use a simple quantile bound. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723c094-96e6-4856-9926-44efdee32d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_threshold = df1.income_lakhs.quantile(0.999)\n",
    "quantile_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf06e41-56ed-4e18-a237-8a95123a28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[df1.income_lakhs<=quantile_threshold].copy()\n",
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427dac5-5792-4e9d-9c32-94b80fbbd5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## income 1->100 lakhs ->reasonable range"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06682dd6-cc0f-4cea-8f45-9de57beddb2f",
   "metadata": {},
   "source": [
    "There are very few outliers in the annual_premium_amount so it is okay to leave them as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fd957-1c0a-4871-9a3f-d422d7a7dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))  # Adjust the size to ensure plots are not squeezed\n",
    "\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    # Locating the correct subplot using integer division and modulus\n",
    "    ax = axs[i // 3, i % 3]  # Row index is i//3, column index is i%3\n",
    "    sns.histplot(df2[column], kde=True, ax=ax)\n",
    "    ax.set_title(column)\n",
    "\n",
    "# If the last subplot axis is unused, you can turn it off\n",
    "if len(numeric_columns) % 3 != 0:\n",
    "    for j in range(len(numeric_columns), 6):  # This will disable any unused subplots\n",
    "        axs.flat[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71827b8-6a64-4d2a-8fc0-fbce7277874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## most income datasets are right skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a06f3-4fc6-4ed6-af2d-bd9ce369cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.histplot(df2.income_lakhs, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6564259c-bfad-448d-8746-eba57907ad8e",
   "metadata": {},
   "source": [
    "### Bivariate Analysis: Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b6bd5-c964-4d62-9170-61c6f3300e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scatterplot -> annual_premium_amount vs age\n",
    "\n",
    "sns.scatterplot(df2, x = 'age', y = 'annual_premium_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa56996e-3a20-4627-be50-bb9b2ba91787",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can se clusters here after observing carefully. \n",
    "## Also another observation-> as age increases, premium also increases. COMMON SENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe741dc-49c8-4100-918a-38d6694d5ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'income_lakhs', 'number_of_dependants', 'genetical_risk']\n",
    "\n",
    "fig, axes = plt.subplots(1, len(numeric_features), figsize=(18, 6))  \n",
    "\n",
    "for ax, column in zip(axes, numeric_features):\n",
    "    sns.scatterplot(x=df2[column], y=df2['annual_premium_amount'], ax=ax)\n",
    "    ax.set_title(f'{column} vs. Annual Premium Amount')\n",
    "    ax.set_xlabel(column)\n",
    "    ax.set_ylabel('Annual Premium Amount')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666037a-a9d0-4ab7-abea-4a00baf14ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## not much correlation between income, premium and no of dependets, premium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01349b-9acc-4592-8109-a66b298bce45",
   "metadata": {},
   "source": [
    "##  Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844723bd-2983-47c9-8cf7-e4172963ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['gender', 'region', 'marital_status', 'bmi_category', 'smoking_status', 'employment_status', 'income_level', 'medical_history', 'insurance_plan']\n",
    "for col in categorical_cols:\n",
    "    print(col, \":\", df2[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268013b-127e-48cb-a994-09c2b69b05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##smoking_status : ['No Smoking' 'Regular' 'Occasional' 'Smoking=0' 'Does Not Smoke' 'Not Smoking'] -> problems\n",
    "\n",
    "df2['smoking_status'].replace({\n",
    "    'Not Smoking': 'No Smoking',\n",
    "    'Does Not Smoke': 'No Smoking',\n",
    "    'Smoking=0': 'No Smoking'\n",
    "}, inplace=True)\n",
    "\n",
    "df2['smoking_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84363163-3c6f-48f5-aa5f-de3c1cb9ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Univariate Analysis: Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811e4bf-c6c4-483b-b367-cd5f01178f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_count = df2['gender'].value_counts(normalize = True)\n",
    "pct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417d741-a92e-4aa3-aae0-0a3ae5d06864",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=pct_count.index, y=pct_count.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf5da7-04a6-45fc-bec3-f285f1c31473",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(18, 18))  \n",
    "axes = axes.flatten()  # Flatten the 2D array of axes into 1D for easier iteration\n",
    "\n",
    "for ax, column in zip(axes, categorical_cols):\n",
    "    # Calculate the percentage distribution of each category\n",
    "    category_counts = df2[column].value_counts(normalize=True) * 100  # normalize=True gives the relative frequencies\n",
    "    \n",
    "    # Plotting the distribution using barplot\n",
    "    sns.barplot(x=category_counts.index, y=category_counts.values, ax=ax)\n",
    "    ax.set_title(f'Percentage Distribution of {column}')\n",
    "    ax.set_ylabel('Percentage of Policyholders (%)')\n",
    "    ax.set_xlabel(column)  # Set xlabel to the column name for clarity\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf8e2a-e46c-46ec-b692-c6d8f34dc33a",
   "metadata": {},
   "source": [
    "### Bivariate Analysis: Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc19fa-e78a-41d9-9f31-1f28b365eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation of gender and smoking status\n",
    "crosstab = pd.crosstab(df2.income_level, df2.insurance_plan)\n",
    "print(crosstab)\n",
    "crosstab.plot(kind = 'bar', stacked = True)\n",
    "plt.title('Income vs Plan')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048ca43-5d17-4970-a943-811616eebe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(crosstab, annot=True, cmap='coolwarm',fmt=\"d\")\n",
    "plt.title('Heatmap of Income vs Plan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a9b0fb-8aea-42c9-8fd8-5b92b457c155",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0a5b0-3242-4bf0-b681-4f10f5dbc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80fbb6b-7298-46fc-8f4d-0ef6bf791b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.medical_history.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f6f2b-ccbb-4cf4-b6bd-8eac181f4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we can calculate and assign some kind of risk score becaus ml models can't process this text values.\n",
    "## more diseases -> more premium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b55c1-e7ae-41d3-aced-78cb3ce0c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the risk scores for each condition.\n",
    "## Logic used here is just an example. In real world, stakeholders decide what to do in situations like these.\n",
    "\n",
    "risk_scores = {\n",
    "    \"diabetes\": 6,\n",
    "    \"heart disease\": 8,\n",
    "    \"high blood pressure\":6,\n",
    "    \"thyroid\": 5,\n",
    "    \"no disease\": 0,\n",
    "    \"none\":0\n",
    "}\n",
    "\n",
    "df2[['disease1', 'disease2']] = df2['medical_history'].str.split(\" & \", expand=True).apply(lambda x: x.str.lower())\n",
    "df2['disease1'].fillna('none', inplace=True)\n",
    "df2['disease2'].fillna('none', inplace=True)\n",
    "df2['total_risk_score'] = 0\n",
    "\n",
    "for disease in ['disease1', 'disease2']:\n",
    "    df2['total_risk_score'] += df2[disease].map(risk_scores)\n",
    "\n",
    "# Normalize the risk score to a range of 0 to 1\n",
    "max_score = df2['total_risk_score'].max()\n",
    "min_score = df2['total_risk_score'].min()\n",
    "df2['normalized_risk_score'] = (df2['total_risk_score'] - min_score) / (max_score - min_score)\n",
    "df2.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45fc73-5067-44f0-bbb7-2bb5c32381ec",
   "metadata": {},
   "source": [
    "### Label encoding text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f9b48-522f-4009-864f-5488c72f962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.insurance_plan.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71210a47-64f8-46c4-a56d-081f1cb06686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['insurance_plan'] = df2['insurance_plan'].map({'Bronze': 1, 'Silver': 2, 'Gold': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7a55e-a034-4bb1-ba6f-07f25cafe796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.income_level.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd335a5-09b3-4f92-8c0c-6b3221f51548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['income_level'] = df2['income_level'].map({'<10L':1, '10L - 25L': 2, '25L - 40L':3, '> 40L':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b1dfb-28d3-4956-b19d-3f933d205b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af55a15-dbc3-43e0-b222-0afe40ca5d11",
   "metadata": {},
   "source": [
    "### Label encoding text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b499a9f-4f35-4ed9-900f-09eea0af8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_cols = ['gender', 'region', 'marital_status', 'bmi_category', 'smoking_status', 'employment_status']\n",
    "df3 = pd.get_dummies(df2, columns=nominal_cols, drop_first=True, dtype=int)\n",
    "df3.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b8f44-b764-42b8-b296-7440131f6ba1",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075bf6f-edd8-4ebd-bb69-760060696c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909a8b1-f956-4620-9d91-f37116a4d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop(['medical_history','disease1', 'disease2', 'total_risk_score'], axis=1)\n",
    "df4.head(3)                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5a532-e5a9-4480-8f9f-7e9df340d83c",
   "metadata": {},
   "source": [
    "#### Calculate VIF for Multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63631973-7dce-448c-9d99-cbb3b6f5ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation analysis\n",
    "cm = df4.corr()\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7285d9-8913-4cdf-8565-58e47c9f8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "## genetical risk has strong correlation (0.62) with premium amount. If we include this feature in the model training, the performance will likely improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa33f7af-be06-4c74-86eb-1b9bb61f163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature scaling\n",
    "\n",
    "X = df4.drop('annual_premium_amount', axis='columns')\n",
    "y = df4['annual_premium_amount']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_to_scale = ['age','number_of_dependants', 'income_level',  'income_lakhs', 'insurance_plan', 'genetical_risk']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X[cols_to_scale] = scaler.fit_transform(X[cols_to_scale])\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0294a-a747-481e-a114-5f244efd4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calculate_vif(data):\n",
    "    vif_df = pd.DataFrame()\n",
    "    vif_df['Column'] = data.columns\n",
    "    vif_df['VIF'] = [variance_inflation_factor(data.values,i) for i in range(data.shape[1])]\n",
    "    return vif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e029bb6-e227-4598-ad4f-4ee9cef0dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334796c7-8eac-410c-84ad-5d75b9f7f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_vif(X.drop('income_level', axis=\"columns\")) ## vif value after droppinh the column with highest vif value looks perfectly fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d60df-108f-48b1-8214-c38d3897685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will drop income_lakhs due to high VIF value\n",
    "X_reduced = X.drop('income_level', axis=\"columns\")\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616af4c-b5f7-4bcc-ac39-5d72b0fb8d60",
   "metadata": {},
   "source": [
    "## 4. Model training    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8772ea-c185-40d4-8c39-4410a258c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.30, random_state=10)\n",
    "\n",
    "# shape of the X_train, X_test, y_train, y_test features\n",
    "print(\"x train: \",X_train.shape)\n",
    "print(\"x test: \",X_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad00f0e-ce5e-407f-8db4-dc529c10d758",
   "metadata": {},
   "source": [
    "#### i. Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46349399-32ca-439f-9370-b3824deeabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "test_score = model_lr.score(X_test, y_test)\n",
    "train_score = model_lr.score(X_train, y_train)\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f14d7d-6cf6-42a7-8891-0b9895eb9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we get a score of 0.98 after adding the gr feature. without it, it was only .58  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafa56e-a581-4464-8a5d-73f66165c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lr.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "print(\"Linear Regression ==> MSE: \", mse_lr, \"RMSE: \", rmse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8698e7-88f0-434e-8fea-615aac4d78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f4dfb-e1b8-4ef7-b080-73fd845a5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec3e06-3075-4a15-9f87-39d8c37e3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=6)\n",
    "model_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c40572-9978-47dd-a4c3-c3fba78222d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model_lr.coef_ ## It tells how much important the features are for the final prediction. In LR, feature importance is simply coefficients.    \n",
    "\n",
    "# Create a DataFrame for easier handling\n",
    "coef_df = pd.DataFrame(feature_importance, index=X_train.columns, columns=['Coefficients'])\n",
    "\n",
    "# Sort the coefficients for better visualization\n",
    "coef_df = coef_df.sort_values(by='Coefficients', ascending=True)\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec85b7e-0eb2-47d5-883c-2179d5c6fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(coef_df.index, coef_df['Coefficients'], color='steelblue')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Feature Importance in Linear Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14194e67-6520-49a7-9a60-6dc68b1fb442",
   "metadata": {},
   "source": [
    "The age feature now has very less importance as the age group is 18-25 where age won't matter for the premium prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4249b2e9-d12d-4f43-8f0c-002308048d77",
   "metadata": {},
   "source": [
    "#### ii. Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58452e32-85d1-421a-9c85-2e0fa09d240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rg = Ridge(alpha=1)\n",
    "model_rg.fit(X_train, y_train)\n",
    "test_score = model_rg.score(X_test, y_test)\n",
    "train_score = model_rg.score(X_train, y_train)\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62901a31-7130-4595-9f43-16f16fe3c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rg.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "print(\"Ridge Regression ==> MSE: \", mse_lr, \"RMSE: \", rmse_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb0e6df-3137-4dd7-bb9f-1ba5133e4585",
   "metadata": {},
   "source": [
    "#### iii. XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78661af-6b13-4253-8f7d-792cc14f125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model_xgb = XGBRegressor(n_estimators=20, max_depth=3)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "test_score = model_xgb.score(X_test, y_test)\n",
    "train_score = model_xgb.score(X_train, y_train)\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5586b652-3e40-4fec-824d-f2fef09691e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_xgb.predict(X_test)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "print(\"XGBoost Regression ==> MSE: \", mse_lr, \"RMSE: \", rmse_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9204908-b60a-40b0-950b-be3fc8dabcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 40, 50],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "random_search = RandomizedSearchCV(model_xgb, param_grid, n_iter=10, cv=3, scoring='r2', random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1de0c-09db-493a-860b-3729cd616925",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e2880-b233-4955-bc10-09f609b6c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "##both lr and xgb are giving approx same value so we'll select linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be729b-519b-4ef6-a067-2d35b1b1f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39bdbc-1d3f-4af6-8164-27bdd17fb73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e32c2f7-3540-4cb0-bee9-97d0db9ad8d7",
   "metadata": {},
   "source": [
    "## 5. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0cf18-9f06-4b38-9844-79ced8953bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can't just rely on r2 score and deploy the model. We need to find the margin of error for each of the sample we are running our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9dbd54-d968-477b-8e05-16634c983063",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "residuals = y_pred - y_test\n",
    "residuals_pct = (residuals / y_test) * 100\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'actual': y_test, \n",
    "    'predicted': y_pred, \n",
    "    'diff': residuals, \n",
    "    'diff_pct': residuals_pct\n",
    "})\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384cb921-c741-4eff-a80f-26f66dadb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(results_df.diff_pct, kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70abdc91-e4e0-4fb5-82e2-b9dbaf2f5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are many records where we are predicting the premium upto 80 percent higher. Basically wrong output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57756ad-38af-4cd1-9ad0-d5f0d485a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_error_threshold = 10  # We can adjust this threshold based on domain knowledge or requirements\n",
    "extreme_results_df = results_df[np.abs(results_df['diff_pct']) > extreme_error_threshold]\n",
    "extreme_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06525069-41d6-4675-a54b-8d664e007f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e1761-464f-4763-a840-35f840ba0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a7ba8-d77a-42ac-94a4-f91d93aaaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_errors_pct = extreme_results_df.shape[0]*100/X_test.shape[0]\n",
    "extreme_errors_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b8038-4174-4f4d-8588-6425e5069c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Down to 2 percert from 73 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f0662-2121-439b-b238-c3dd469d4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_results_df[abs(extreme_results_df.diff_pct)>50].sort_values(\"diff_pct\",ascending=False).shape ## more than 50 percent error margin in extreme_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190a8abd-0c6e-4554-9b68-396740c38d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_results_df[abs(extreme_results_df.diff_pct)>50].sort_values(\"diff_pct\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e509008-f7d7-4ff8-b1d4-7f15506aae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "##There will be about 549 customers whom we will overcharge or underchage by more than 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e27556-6b1e-417f-9c10-2f0b1ca12b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_results_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8063d94e-593d-4366-8b03-c27b3e01de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_errors_df = X_test.loc[extreme_results_df.index]\n",
    "extreme_errors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d2c9a-aaea-45ed-8ff6-0627bb892a39",
   "metadata": {},
   "source": [
    "## 6. Exporting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de13cdd-0703-4be7-aeb1-8c470e92838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(best_model, \"artifacts/model_young.joblib\") ## saving the model\n",
    "scaler_with_cols = {   ## Our model is training on the scaled data, not the original data so we'll also have to saved this so that during the prediction, the scaling can be done\n",
    "    'scaler': scaler,\n",
    "    'cols_to_scale': cols_to_scale\n",
    "}\n",
    "dump(scaler_with_cols, \"artifacts/scaler_young.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4f674-d3ef-49ad-bfa6-7955f0aeb6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
